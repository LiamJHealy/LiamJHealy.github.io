I"<<h3 id="dropout-regularization"><center>Dropout regularization</center></h3>

<p>Dropout is a commonly used regularization method, it can be described by the diagram below: only part of the neurons in the whole network are updated. Mathematically, we apply some possibility \(p\)(we use 0.5) to a neuron to keep it active or keep it asleep:</p>

<p><img src="\images\machine_learning\dropout.png" alt="dropout" /></p>

<!-- more -->

<p>Normally we only apply the dropout regularization to the middle layers, but you can also apply it to the input layer, which means adding a binary mask to the input data.</p>

<p>What’s really important is that we are not dropping out neurons for prediction! It brings a problem: the neurons in prediction phase is respecting the same data as the training phase but it is not, in the training phase neurons only received 50% outputs from the last layer(we use \(p=0.5\)), which means the strength of the input signal of each neuron during the prediction phase is 2 times of the signal in training phase.</p>

<p>So we should reduce the signal strength for prediction: all neurons’ outputs will be scaled by \(p\). Practically:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span style="color: #586e75">p</span> <span style="color: #93a1a1">=</span> <span style="color: #859900">0.5</span> <span style="color: #657b83"># probability of keeping a unit active. higher = less dropout
</span>
<span style="color: #6c71c4">def</span> <span style="color: #586e75">train_step</span><span style="color: #93a1a1">(</span><span style="color: #586e75">X</span><span style="color: #93a1a1">):</span>
  <span style="color: #859900">""" X contains the data """</span>
  
  <span style="color: #657b83"># forward pass for example 3-layer neural network
</span>  <span style="color: #586e75">H1</span> <span style="color: #93a1a1">=</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">maximum</span><span style="color: #93a1a1">(</span><span style="color: #859900">0</span><span style="color: #93a1a1">,</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">dot</span><span style="color: #93a1a1">(</span><span style="color: #586e75">W1</span><span style="color: #93a1a1">,</span> <span style="color: #586e75">X</span><span style="color: #93a1a1">)</span> <span style="color: #93a1a1">+</span> <span style="color: #586e75">b1</span><span style="color: #93a1a1">)</span>
  <span style="color: #586e75">U1</span> <span style="color: #93a1a1">=</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">random</span><span style="color: #93a1a1">.</span><span style="color: #586e75">rand</span><span style="color: #93a1a1">(</span><span style="color: #93a1a1">*</span><span style="color: #586e75">H1</span><span style="color: #93a1a1">.</span><span style="color: #586e75">shape</span><span style="color: #93a1a1">)</span> <span style="color: #93a1a1">&lt;</span> <span style="color: #586e75">p</span> <span style="color: #657b83"># first dropout mask
</span>  <span style="color: #586e75">H1</span> <span style="color: #93a1a1">*=</span> <span style="color: #586e75">U1</span> <span style="color: #657b83"># drop!
</span>  <span style="color: #586e75">H2</span> <span style="color: #93a1a1">=</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">maximum</span><span style="color: #93a1a1">(</span><span style="color: #859900">0</span><span style="color: #93a1a1">,</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">dot</span><span style="color: #93a1a1">(</span><span style="color: #586e75">W2</span><span style="color: #93a1a1">,</span> <span style="color: #586e75">H1</span><span style="color: #93a1a1">)</span> <span style="color: #93a1a1">+</span> <span style="color: #586e75">b2</span><span style="color: #93a1a1">)</span>
  <span style="color: #586e75">U2</span> <span style="color: #93a1a1">=</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">random</span><span style="color: #93a1a1">.</span><span style="color: #586e75">rand</span><span style="color: #93a1a1">(</span><span style="color: #93a1a1">*</span><span style="color: #586e75">H2</span><span style="color: #93a1a1">.</span><span style="color: #586e75">shape</span><span style="color: #93a1a1">)</span> <span style="color: #93a1a1">&lt;</span> <span style="color: #586e75">p</span> <span style="color: #657b83"># second dropout mask
</span>  <span style="color: #586e75">H2</span> <span style="color: #93a1a1">*=</span> <span style="color: #586e75">U2</span> <span style="color: #657b83"># drop!
</span>  <span style="color: #586e75">out</span> <span style="color: #93a1a1">=</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">dot</span><span style="color: #93a1a1">(</span><span style="color: #586e75">W3</span><span style="color: #93a1a1">,</span> <span style="color: #586e75">H2</span><span style="color: #93a1a1">)</span> <span style="color: #93a1a1">+</span> <span style="color: #586e75">b3</span>
  <span style="color: #657b83"># backward pass: compute gradients... (not shown)
</span>  <span style="color: #657b83"># perform parameter update... (not shown)
</span><span style="color: #6c71c4">def</span> <span style="color: #586e75">predict</span><span style="color: #93a1a1">(</span><span style="color: #586e75">X</span><span style="color: #93a1a1">):</span>
  <span style="color: #657b83"># ensembled forward pass
</span>  <span style="color: #586e75">H1</span> <span style="color: #93a1a1">=</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">maximum</span><span style="color: #93a1a1">(</span><span style="color: #859900">0</span><span style="color: #93a1a1">,</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">dot</span><span style="color: #93a1a1">(</span><span style="color: #586e75">W1</span><span style="color: #93a1a1">,</span> <span style="color: #586e75">X</span><span style="color: #93a1a1">)</span> <span style="color: #93a1a1">+</span> <span style="color: #586e75">b1</span><span style="color: #93a1a1">)</span> <span style="color: #93a1a1">*</span> <span style="color: #586e75">p</span> <span style="color: #657b83"># NOTE: scale the activations
</span>  <span style="color: #586e75">H2</span> <span style="color: #93a1a1">=</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">maximum</span><span style="color: #93a1a1">(</span><span style="color: #859900">0</span><span style="color: #93a1a1">,</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">dot</span><span style="color: #93a1a1">(</span><span style="color: #586e75">W2</span><span style="color: #93a1a1">,</span> <span style="color: #586e75">H1</span><span style="color: #93a1a1">)</span> <span style="color: #93a1a1">+</span> <span style="color: #586e75">b2</span><span style="color: #93a1a1">)</span> <span style="color: #93a1a1">*</span> <span style="color: #586e75">p</span> <span style="color: #657b83"># NOTE: scale the activations
</span>  <span style="color: #586e75">out</span> <span style="color: #93a1a1">=</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">dot</span><span style="color: #93a1a1">(</span><span style="color: #586e75">W3</span><span style="color: #93a1a1">,</span> <span style="color: #586e75">H2</span><span style="color: #93a1a1">)</span> <span style="color: #93a1a1">+</span> <span style="color: #586e75">b3</span>
</code></pre></div></div>

<p>As prediction usually has high requirement on performance, we don’t want an additional multiplication after each neuron, so it will be better to put the scaling at training time, which is called inverted dropout:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span style="color: #859900">""" 
Inverted Dropout: Recommended implementation example.
We drop and scale at train time and don't do anything at test time.
"""</span>

<span style="color: #586e75">p</span> <span style="color: #93a1a1">=</span> <span style="color: #859900">0.5</span> <span style="color: #657b83"># probability of keeping a unit active. higher = less dropout
</span>
<span style="color: #6c71c4">def</span> <span style="color: #586e75">train_step</span><span style="color: #93a1a1">(</span><span style="color: #586e75">X</span><span style="color: #93a1a1">):</span>
  <span style="color: #657b83"># forward pass for example 3-layer neural network
</span>  <span style="color: #586e75">H1</span> <span style="color: #93a1a1">=</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">maximum</span><span style="color: #93a1a1">(</span><span style="color: #859900">0</span><span style="color: #93a1a1">,</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">dot</span><span style="color: #93a1a1">(</span><span style="color: #586e75">W1</span><span style="color: #93a1a1">,</span> <span style="color: #586e75">X</span><span style="color: #93a1a1">)</span> <span style="color: #93a1a1">+</span> <span style="color: #586e75">b1</span><span style="color: #93a1a1">)</span>
  <span style="color: #586e75">U1</span> <span style="color: #93a1a1">=</span> <span style="color: #93a1a1">(</span><span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">random</span><span style="color: #93a1a1">.</span><span style="color: #586e75">rand</span><span style="color: #93a1a1">(</span><span style="color: #93a1a1">*</span><span style="color: #586e75">H1</span><span style="color: #93a1a1">.</span><span style="color: #586e75">shape</span><span style="color: #93a1a1">)</span> <span style="color: #93a1a1">&lt;</span> <span style="color: #586e75">p</span><span style="color: #93a1a1">)</span> <span style="color: #93a1a1">/</span> <span style="color: #586e75">p</span> <span style="color: #657b83"># first dropout mask. Notice /p!
</span>  <span style="color: #586e75">H1</span> <span style="color: #93a1a1">*=</span> <span style="color: #586e75">U1</span> <span style="color: #657b83"># drop!
</span>  <span style="color: #586e75">H2</span> <span style="color: #93a1a1">=</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">maximum</span><span style="color: #93a1a1">(</span><span style="color: #859900">0</span><span style="color: #93a1a1">,</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">dot</span><span style="color: #93a1a1">(</span><span style="color: #586e75">W2</span><span style="color: #93a1a1">,</span> <span style="color: #586e75">H1</span><span style="color: #93a1a1">)</span> <span style="color: #93a1a1">+</span> <span style="color: #586e75">b2</span><span style="color: #93a1a1">)</span>
  <span style="color: #586e75">U2</span> <span style="color: #93a1a1">=</span> <span style="color: #93a1a1">(</span><span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">random</span><span style="color: #93a1a1">.</span><span style="color: #586e75">rand</span><span style="color: #93a1a1">(</span><span style="color: #93a1a1">*</span><span style="color: #586e75">H2</span><span style="color: #93a1a1">.</span><span style="color: #586e75">shape</span><span style="color: #93a1a1">)</span> <span style="color: #93a1a1">&lt;</span> <span style="color: #586e75">p</span><span style="color: #93a1a1">)</span> <span style="color: #93a1a1">/</span> <span style="color: #586e75">p</span> <span style="color: #657b83"># second dropout mask. Notice /p!
</span>  <span style="color: #586e75">H2</span> <span style="color: #93a1a1">*=</span> <span style="color: #586e75">U2</span> <span style="color: #657b83"># drop!
</span>  <span style="color: #586e75">out</span> <span style="color: #93a1a1">=</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">dot</span><span style="color: #93a1a1">(</span><span style="color: #586e75">W3</span><span style="color: #93a1a1">,</span> <span style="color: #586e75">H2</span><span style="color: #93a1a1">)</span> <span style="color: #93a1a1">+</span> <span style="color: #586e75">b3</span>
  
  <span style="color: #657b83"># backward pass: compute gradients... (not shown)
</span>  <span style="color: #657b83"># perform parameter update... (not shown)
</span>  
<span style="color: #6c71c4">def</span> <span style="color: #586e75">predict</span><span style="color: #93a1a1">(</span><span style="color: #586e75">X</span><span style="color: #93a1a1">):</span>
  <span style="color: #657b83"># ensembled forward pass
</span>  <span style="color: #586e75">H1</span> <span style="color: #93a1a1">=</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">maximum</span><span style="color: #93a1a1">(</span><span style="color: #859900">0</span><span style="color: #93a1a1">,</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">dot</span><span style="color: #93a1a1">(</span><span style="color: #586e75">W1</span><span style="color: #93a1a1">,</span> <span style="color: #586e75">X</span><span style="color: #93a1a1">)</span> <span style="color: #93a1a1">+</span> <span style="color: #586e75">b1</span><span style="color: #93a1a1">)</span> <span style="color: #657b83"># no scaling necessary
</span>  <span style="color: #586e75">H2</span> <span style="color: #93a1a1">=</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">maximum</span><span style="color: #93a1a1">(</span><span style="color: #859900">0</span><span style="color: #93a1a1">,</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">dot</span><span style="color: #93a1a1">(</span><span style="color: #586e75">W2</span><span style="color: #93a1a1">,</span> <span style="color: #586e75">H1</span><span style="color: #93a1a1">)</span> <span style="color: #93a1a1">+</span> <span style="color: #586e75">b2</span><span style="color: #93a1a1">)</span>
  <span style="color: #586e75">out</span> <span style="color: #93a1a1">=</span> <span style="color: #586e75">np</span><span style="color: #93a1a1">.</span><span style="color: #586e75">dot</span><span style="color: #93a1a1">(</span><span style="color: #586e75">W3</span><span style="color: #93a1a1">,</span> <span style="color: #586e75">H2</span><span style="color: #93a1a1">)</span> <span style="color: #93a1a1">+</span> <span style="color: #586e75">b3</span>
</code></pre></div></div>

<p>This is how it works in the program:</p>

<p><img src="\images\machine_learning\dropoutmask.jpg" alt="dropoutmask" /></p>
:ET